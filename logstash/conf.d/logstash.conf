input {
#Below are defined inputs from redis for weblogic logs
    redis {
   		host      => "10.129.19.31"
   		port      => 6379
   		data_type => "list"
   		key       => "weblogic"
  	}
#Comment above and uncomment below for second node
#  	redis {
#   		host      => "10.129.19.32"
#   		port      => 6379
#   		data_type => "list"
#   		key       => "weblogic"
#  	}
#Comment above and uncomment below for third node
#  	redis {
#   		host      => "10.129.19.33"
#   		port      => 6379
#   		data_type => "list"
#   		key       => "weblogic"
#  	}
#Below are defined inputs from redis for apache logs
  	redis {
   		host      => "10.129.19.31"
   		port      => 6379
   		data_type => "list"
   		key       => "apache"
  	}
#  	redis {
#   		host      => "10.129.19.32"
#   		port      => 6379
#   		data_type => "list"
#   		key       => "apache"
#  	}
#  	redis {
#   		host      => "10.129.19.33"
#   		port      => 6379
#   		data_type => "list"
#   		key       => "apache"
#  	}
#Below are defined inputs from redis for hsapp logs
    redis {
   		host      => "10.129.19.31"
   		port      => 6379
   		data_type => "list"
   		key       => "hsapp"
  	}
#Comment above and uncomment below for second node
#  	redis {
#   		host      => "10.129.19.32"
#   		port      => 6379
#   		data_type => "list"
#   		key       => "hsapp"
#  	}
#Comment above and uncomment below for third node
#  	redis {
#   		host      => "10.129.19.33"
#   		port      => 6379
#   		data_type => "list"
#   		key       => "hsapp"
#  	}
}

filter {
    #Below is defined log filtering for weblogic server logs
    if [type] == "wlserver" {
        multiline {
     		pattern => "^####"
      		negate  => true
      		what    => "previous"
    	}
    	grok {
		    patterns_dir => "./patterns"
		    match => { "message" => "(?m)%{WLS_SRV_LOG}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
		    uppercase => [ "Wls_Severity" ]
		    add_tag => [ "%{type}" ]
  		}
  	    date {
                        # localization mess...
                        match => ["Wls_Timestamp",
                                "MMM d, yyyy h:mm:ss a z",
                                "MMM d, yyyy h:mm:ss a 'ALMT'",
                                "MMM d, yyyy h:mm:ss a 'WIT'",
                                "MMM dd, yyyy h:mm:ss a 'CEST'",
                                "MMM dd, yyyy h:mm:ss a 'CET'",
                                "dd.MM.yyyy H:mm:ss z",
                                "dd.MM.yyyy H:mm:ss a 'CEST'",
                                "dd.MM.yyyy H:mm:ss 'CEST'",
                                "dd.MM.yyyy H:mm:ss 'ALMT'"
                        ]
        }
  		if ("_grokparsefailure" in [tags]) {
      		grok {
                match => { "message" => "(?m)%{GREEDYDATA:Wls_MessageText}" }
        	}
	    }
	}
	if [type] == "wlout" {
        #Below is defined log filtering for weblogic server out
	    multiline {
     		pattern => "^<%{MONTHDAY}"
      		negate  => true
      		what    => "previous"
    	}
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "(?m)%{WLS_OUT}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		add_tag => [ "%{type}" ]
		    uppercase => [ "Wls_Severity" ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:Wls_MessageText}" }
        	}
	    }
	}
	if [type] == "wlerr" {
        #Below is defined log filtering for weblogic server error out
	    multiline {
     		pattern => "^%{WORD}"
      		negate  => true
      		what    => "previous"
    	}
    	grok {
		    patterns_dir => "./patterns"
		    match => { "message" => "(?m)%{WLS_ERR}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		add_tag => [ "%{type}" ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
                	match => { "message" => "(?m)%{GREEDYDATA:Wls_Err}" }
        	}
	    }
	}
	if [type] == "gc" {
	    #Below is defined log filtering for garbage collector
    	grok {
		    patterns_dir => "./patterns"
		    match => { "message" => "(?m)%{JAVA_GC}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		add_tag => [ "%{type}" ]
    		gsub => [ "@message", "\u0000", " " ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
                	match => { "message" => "(?m)%{GREEDYDATA:JavaGC_Message}" }
        	}
	    }
	}
	if [type] == "wlacc" {
	    #Below is defined log filtering for weblogic server access log
    	grok {
		    patterns_dir => "./patterns"
		    match => { "message" => "(?m)%{WLS_ACCESS}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		add_tag => [ "%{type}" ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
                	match => { "message" => "(?m)%{GREEDYDATA:WlsHttp_Request}" }
        	}
	    }
	}
	if [type] == "osbserver" {
	    #Below is defined log filtering for OSB log
        multiline {
     		pattern => "^%{DAY}"
      		negate  => true
      		what    => "previous"
    	}
    	grok {
		    patterns_dir => "./patterns"
		    match => { "message" => "(?m)%{OSB_SRV_LOG}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
		    add_tag => [ "%{type}" ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
                match => { "message" => "(?m)%{GREEDYDATA:Osb_MessageText}" }
        	}
	    }
	}
	if [type] == "nm" {
	    #Below is defined log filtering for NodeManager log
	    multiline {
     		pattern => "^<%{MONTH}"
      		negate  => true
      		what    => "previous"
    	}
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "(?m)%{NM_LOG}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		add_tag => [ "%{type}" ]
		    uppercase => [ "Nm_Severity" ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:Nm_MessageText}" }
        	}
	    }
	}
	if [type] == "dbauth" {
	    #Below is defined log filtering for DbAuth provider
	    multiline {
     		pattern => "^%{DAY}"
      		negate  => true
      		what    => "previous"
    	}
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "(?m)%{DB_AUTH_LOG}" }
		}
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		gsub => [ "DbAuth_AdditionalText", "\n", "," ]
    		add_tag => [ "%{type}" ]
		    uppercase => [ "DbAuth_Severity" ]
  		}
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:DbAuth_MessageText}" }
        	}
	    }
	}
	if [type] == "apache_access" {
	    #Below is defined log filtering for apache access log
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "%{APACHE_ACCESS_LOG}" }
		}
		grok {
            match => [ "path", "%{APACHE_PATH}" ]
        }
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		uppercase => [ "Environment" ]
    		uppercase => [ "Country" ]
    		add_tag => [ "%{type}" ]
  		}
  		date {
            # Adjusting delay between deliver row to server
            match => ["Apache_Timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
        }
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:Apache_MessageText}" }
        	}
	    }
	}
	if [type] == "apache_error" {
	    #Below is defined log filtering for apache error log
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "%{APACHE_ERROR_LOG}" }
		}
		grok {
            match => [ "path", "%{APACHE_PATH}" ]
        }
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		uppercase => [ "Environment" ]
    		uppercase => [ "Country" ]
    		add_tag => [ "%{type}" ]
  		}
  		date {
            # Adjusting delay between deliver row to server
            match => ["Apache_Timestamp", "EEE MMM dd HH:mm:ss yyyy"]
        }
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:Apache_MessageText}" }
        	}
	    }
	}
	if [type] == "apache_access_administ" {
	    #Below is defined log filtering for apache access log
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "%{APACHE_ACCESS_LOG}" }
		}
		grok {
            match => [ "path", "%{APACHE_PATH_ADMINIST}" ]
        }
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		uppercase => [ "Environment" ]
    		uppercase => [ "Country" ]
    		add_tag => [ "%{type}" ]
  		}
  		date {
            # Adjusting delay between deliver row to server
            match => ["Apache_Timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
        }
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:Apache_MessageText}" }
        	}
	    }
	}
	if [type] == "apache_error_administ" {
	    #Below is defined log filtering for apache error log
    	grok {
		    patterns_dir => "./patterns"
			match => { "message" => "%{APACHE_ERROR_LOG}" }
		}
		grok {
            match => [ "path", "%{APACHE_PATH_ADMINIST}" ]
        }
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		uppercase => [ "Environment" ]
    		uppercase => [ "Country" ]
    		add_tag => [ "%{type}" ]
  		}
  		date {
            # Adjusting delay between deliver row to server
            match => ["Apache_Timestamp", "EEE MMM dd HH:mm:ss yyyy"]
        }
  		if ("_grokparsefailure" in [tags]) {
      		grok {
      		match => { "message" => "(?m)%{GREEDYDATA:Apache_MessageText}" }
        	}
	    }
	}
	if [type] == "hsapp" {
	    #Below is defined log filtering for hosel apps
    	if "processed" not in [tags] {
            grok {
                match => { "message" => "%{HSAPP1}"}
                patterns_dir => ["./patterns"]
                add_tag => ["processed", "HSAPP1"]
                }
        }
        if "processed" not in [tags] {
            grok {
                match => { "message" => "%{HSAPP2}"}
                patterns_dir => ["./patterns"]
                remove_tag => ["_grokparsefailure"]
                add_tag => ["processed", "HSAPP2"]
                }
        }
        if "processed" not in [tags] {
            grok {
                match => { "message" => "%{HSAPP3}"}
                patterns_dir => ["./patterns"]
                add_tag => ["processed","HSAPP3"]
            }
        }
    	mutate {
    		rename => [ "host", "Unix_Hostname" ]
    		add_tag => [ "%{type}" ]
  		}
  		date {
            # Adjusting delay between deliver row to server
            match => ["TIMESTAMP", "YYYY-MM-dd HH:mm:Ss,SSS"]
        }
	}
}
#Workaround for new veresion of KIBANA-4.0.0-beta3
#Node 1
output {
        elasticsearch_http {
        host => "logservice01.cz.nonprod"
        }
}
#Node 2
#output {
#        elasticsearch_http {
#        host => "logservice02.cz.nonprod"
#        }
#}
#Node 3
#output {
#        elasticsearch_http {
#        host => "logservice03.cz.nonprod"
#        }
#}
#Below is defined output sending to ElasticSearch
#output {
#    elasticsearch {
#    cluster => "es-nonprod"
#    host => "logservice01.cz.nonprod"
#    port => "9300"
#    protocol => "node"
#  }
#}
#Comment above and uncomment below for second node
#output {
#    elasticsearch {
#    cluster => "es-nonprod"
#    host => "logservice02.cz.nonprod"
#    port => "9300"
#    protocol => "node"
#  }
#}
#Comment above and uncomment below for third node
#output {
#    elasticsearch {
#    cluster => "es-nonprod"
#    host => "logservice03.cz.nonprod"
#    port => "9300"
#    protocol => "node"
#  }
#}